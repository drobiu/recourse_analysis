{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from carla.data.catalog import OnlineCatalog\n",
    "from carla import MLModelCatalog\n",
    "from carla.recourse_methods import Clue\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "num = 10\n",
    "data_name = \"compas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new_model(dataset):\n",
    "    model = MLModelCatalog(dataset, \"ann\", backend=\"pytorch\")\n",
    "    model.train(\n",
    "        learning_rate = 0.001,\n",
    "        epochs = 10,\n",
    "        max_depth = 50,\n",
    "        n_estimators = 50,\n",
    "        batch_size = 20,\n",
    "        force_train = True\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fefa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataset(dataset, factuals, counterfactuals):\n",
    "    fac_ind = []\n",
    "#     for index, row in factuals.iterrows():\n",
    "#         fac_ind.append(index)\n",
    "#     for index, row in counterfactuals.iterrows():\n",
    "#         dataset.loc[index] = counterfactuals.loc[index]\n",
    "        \n",
    "    for ((i_f, r_f), (i_c, r_c)) in zip(factuals.iterrows(), counterfactuals.iterrows()):\n",
    "        if len(counterfactuals.loc[i_c].dropna()) > 0:\n",
    "            dataset.loc[i_f] = counterfactuals.loc[i_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e863c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_recourse_method(method):\n",
    "    rm = None\n",
    "    if method == \"clue\":\n",
    "        hyperparams = {\n",
    "                \"data_name\": data_name,\n",
    "                \"train_vae\": True,\n",
    "                \"width\": 10,\n",
    "                \"depth\": 3,\n",
    "                \"latent_dim\": 12,\n",
    "                \"batch_size\": 64,\n",
    "                \"epochs\": 1,\n",
    "                \"lr\": 0.001,\n",
    "                \"early_stop\": 20,\n",
    "            }\n",
    "\n",
    "        # load a recourse model and pass black box model\n",
    "        rm = Clue(dataset, model, hyperparams)\n",
    "        \n",
    "    return rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    pred = model.predict(data._df)\n",
    "    return np.where(pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7dfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_f1_score(model, data):\n",
    "    score = f1_score(np.array(data._df[data.target]), predict(model, data))\n",
    "    print(f\"F1 score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c3ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(model, data):\n",
    "    score = accuracy_score(np.array(data._df[data.target]), predict(model, data))\n",
    "    print(f\"Accuracy score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(model_pre, model_post, data):\n",
    "    print(\"Before recourse:\")\n",
    "    print_f1_score(model_pre, data)\n",
    "    print_accuracy(model_pre, data)\n",
    "    print(\"\\nAfter recourse:\")\n",
    "    print_f1_score(model_post, data)\n",
    "    print_accuracy(model_post, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = OnlineCatalog(data_name)\n",
    "\n",
    "# train a model on the dataset\n",
    "model = train_new_model(dataset)\n",
    "\n",
    "# generate counterfactual samples\n",
    "factuals = predict_negative_instances(model, dataset._df).sample(num)\n",
    "print(\"Number of factuals\", len(factuals))\n",
    "\n",
    "pre = model.predict(factuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ee989",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = train_recourse_method(\"clue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactuals = rm.get_counterfactuals(factuals)\n",
    "print(\"Number of counterfactuals:\", len(counterfactuals.dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a new dataset\n",
    "d_c = OnlineCatalog(data_name)\n",
    "\n",
    "# replace factuals with counterfactuals\n",
    "update_dataset(d_c._df, factuals, counterfactuals)\n",
    "\n",
    "# train the new model\n",
    "model2 = train_new_model(d_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6892c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(model, model2, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2855cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(factuals['age'], factuals['length_of_stay'], c=factuals['score'], marker='o')\n",
    "# plt.xlim([0, 0.1])\n",
    "# plt.show()\n",
    "\n",
    "plt.scatter(counterfactuals['age'], counterfactuals['length_of_stay'], c=counterfactuals['score'], marker='s')\n",
    "# plt.xlim([0, 0.1])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3c8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recourse2",
   "language": "python",
   "name": "recourse2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
