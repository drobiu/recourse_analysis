{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ea1ef9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from carla.data.catalog import CsvCatalog\n",
    "from carla import MLModelCatalog\n",
    "from carla.recourse_methods import Clue, Wachter\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "from carla.evaluation.benchmark import Benchmark\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "import imageio\n",
    "import timeit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from recourse_util import update_dataset, predict, print_scores \n",
    "\n",
    "num = 10\n",
    "iter_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "55abea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset):\n",
    "    training_params = {\"lr\": 0.005, \"epochs\": 4, \"batch_size\": 1, \"hidden_size\": [5]}\n",
    "\n",
    "    model = MLModelCatalog(\n",
    "        dataset,\n",
    "        model_type=\"ann\",\n",
    "        load_online=False,\n",
    "        backend=\"pytorch\"\n",
    "    )\n",
    "\n",
    "    model.train(\n",
    "        learning_rate=training_params[\"lr\"],\n",
    "        epochs=training_params[\"epochs\"],\n",
    "        batch_size=training_params[\"batch_size\"],\n",
    "        hidden_size=training_params[\"hidden_size\"],\n",
    "        force_train=True\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "29221e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    dataset = CsvCatalog(\n",
    "#         file_path='datasets/bimodal_dataset_1.csv',\n",
    "#         file_path='datasets/unimodal_dataset_1.csv',\n",
    "        file_path='datasets/unimodal_dataset_2.csv',\n",
    "        categorical=[],\n",
    "        continuous=['feature1', 'feature2'],\n",
    "        immutables=[],\n",
    "        target='target'\n",
    "    )\n",
    "\n",
    "    data_name = 'custom'\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b4c69bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_recourse_method(method, model, dataset=None, data_name=None, hyperparams=None):\n",
    "    rm = None\n",
    "    if method == \"clue\":\n",
    "        hyperparams = {\n",
    "                \"data_name\": data_name,\n",
    "                \"train_vae\": True,\n",
    "                \"width\": 10,\n",
    "                \"depth\": 3,\n",
    "                \"latent_dim\": 12,\n",
    "                \"batch_size\": 4,\n",
    "                \"epochs\": 5,\n",
    "                \"lr\": 0.0001,\n",
    "                \"early_stop\": 20,\n",
    "            }\n",
    "\n",
    "        # load a recourse model and pass black box model\n",
    "        rm = Clue(dataset, model, hyperparams)\n",
    "        \n",
    "    else:\n",
    "        hyperparams = {\n",
    "            \"loss_type\": \"BCE\",\n",
    "            \"t_max_min\": 0.5/60\n",
    "        }\n",
    "\n",
    "        # load a recourse model and pass black box model\n",
    "        rm = Wachter(model, hyperparams)\n",
    "        \n",
    "        \n",
    "    return rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7d297e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(data):\n",
    "\n",
    "    plt.scatter(data['feature1'], data['feature2'], c=data['target'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9ba570ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factuals(dataset, sample_num=5, max_m_iter=3):\n",
    "    m_iter = 0\n",
    "    model = train_model(dataset)\n",
    "    factuals = predict_negative_instances(model, dataset._df)\n",
    "    n_factuals = len(factuals)\n",
    "    while (m_iter < max_m_iter and n_factuals < sample_num):\n",
    "        model = train_model(dataset)\n",
    "        factuals = predict_negative_instances(model, dataset._df)\n",
    "        n_factuals = len(factuals)\n",
    "        m_iter += 1\n",
    "        \n",
    "    return model, factuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4c537c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_experiment_iteration(method, dataset, model, factuals, results, draw_state=False):\n",
    "    print(\"Number of factuals\", len(factuals))\n",
    "    \n",
    "#     add_data_statistics(model, dataset, results)\n",
    "    \n",
    "    if method == 'clue':\n",
    "        rm = train_recourse_method('clue', model, dataset, data_name='custom')\n",
    "    else:\n",
    "        rm = train_recourse_method('wachter', model)\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    counterfactuals = rm.get_counterfactuals(factuals)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"Number of counterfactuals:\", len(counterfactuals.dropna()))\n",
    "    \n",
    "    update_dataset(dataset, factuals, counterfactuals)\n",
    "    \n",
    "#     benchmark = CustomBenchmark(model, rm, factuals, counterfactuals, start - stop)\n",
    "#     results['benchmark'] = benchmark.run_benchmark()\n",
    "    \n",
    "    add_data_statistics(model, dataset, results)\n",
    "    \n",
    "    if draw_state:\n",
    "        draw(dataset._df)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9a8acd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "def get_empty_results():\n",
    "    return {\n",
    "        'datasets': [],\n",
    "        'means': [],\n",
    "        'covariances': [],\n",
    "        'clustering': [],\n",
    "        'accuracies': [],\n",
    "        'f1_scores': [],\n",
    "        'benchmark': []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "58e261c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_statistics(model, dataset, results):\n",
    "    results['datasets'].append(dataset._df.copy())\n",
    "    results['means'].append(dataset._df[dataset.continuous].mean().to_numpy())\n",
    "    results['covariances'].append(dataset._df[dataset.continuous].cov().to_numpy())\n",
    "    results['clustering'].append(find_elbow(dataset))\n",
    "    results['accuracies'].append(accuracy_score(np.array(dataset._df[dataset.target]), predict(model, dataset)))\n",
    "    results['f1_scores'].append(f1_score(np.array(dataset._df[dataset.target]), predict(model, dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e5af2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_elbow(dataset, n=10):\n",
    "    ch_metrics = []\n",
    "    x = dataset.df[dataset.continuous]\n",
    "    \n",
    "    for i in range(2, n):\n",
    "        model = KMeans(n_clusters=i, random_state=1).fit(x)\n",
    "        ch_metrics.append(metrics.calinski_harabasz_score(x, model.labels_))\n",
    "        \n",
    "    return ch_metrics.index(np.max(ch_metrics)) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d55c8fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_animation(results, method='clue'):\n",
    "    data = results[method]['datasets']\n",
    "    names = [f\"images/{method}{str(n)}.png\" for n in range(len(data))]\n",
    "    \n",
    "    for i, name in enumerate(names):\n",
    "        for _ in range(1):\n",
    "            plt.scatter(data[i]['feature1'], data[i]['feature2'], c=data[i]['target']) \n",
    "            \n",
    "            plt.text(0, 0, \"data_name\", ha='left', va='center')     \n",
    "            plt.text(1, 1, f\"iteration {i+1}\", ha='right', va='center')    \n",
    "            plt.text(0, 1, \"clue\", ha='left', va='center')     \n",
    "            plt.text(1, 0, f\"2 samples\", ha='right', va='center')\n",
    "\n",
    "            plt.savefig(name)\n",
    "            plt.close()\n",
    "        \n",
    "    gif_path = f\"gifs/{method}_gif_{iter_id}.gif\"\n",
    "        \n",
    "    with imageio.get_writer(f'{gif_path}', mode='I') as writer:\n",
    "        for filename in names:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "            \n",
    "    print(f\"Saved gif to {gif_path}\")\n",
    "        \n",
    "    for filename in set(names):\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bbf052c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBenchmark(Benchmark):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mlmodel,\n",
    "        recourse_method,\n",
    "        factuals: pd.DataFrame,\n",
    "        counterfactuals: pd.DataFrame,\n",
    "        timer\n",
    "    ) -> None:\n",
    "\n",
    "        self._mlmodel = mlmodel\n",
    "        self._recourse_method = recourse_method\n",
    "        self._counterfactuals = counterfactuals.copy()\n",
    "        self._timer = timer\n",
    "\n",
    "        # Avoid using scaling and normalizing more than once\n",
    "        if isinstance(mlmodel, MLModelCatalog):\n",
    "            self._mlmodel.use_pipeline = False  # type: ignore\n",
    "\n",
    "        self._factuals = factuals.copy()\n",
    "    \n",
    "#     def compute_ynn(self) -> pd.DataFrame:\n",
    "#         return self.super().compute_ynn()\n",
    "    \n",
    "#     def compute_average_time(self) -> pd.DataFrame:\n",
    "#         return self.super().compute_average_time()\n",
    "    \n",
    "#     def compute_distances(self) -> pd.DataFrame:\n",
    "#         return self.super().compute_distances()\n",
    "    \n",
    "#     def compute_constraint_violation(self) -> pd.DataFrame:\n",
    "#         return self.super().compute_constraint_violation()\n",
    "    \n",
    "#     def compute_redundancy(self) -> pd.DataFrame:\n",
    "#         return self.super().compute_redundancy()\n",
    "    \n",
    "#     def compute_success_rate(self) -> pd.DataFrame:\n",
    "#         return self.super().compute_success_rate()\n",
    "    \n",
    "#     def run_benchmark(self) -> pd.DataFrame:\n",
    "#         return self.super().run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e54f4ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance on test set 0.5133333333333333, balance on test set 0.46\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.7193 Acc: 0.5133\n",
      "\n",
      "test Loss: 0.6944 Acc: 0.4600\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.6819 Acc: 0.5600\n",
      "\n",
      "test Loss: 0.6502 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.5971 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.5147 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.4550 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.3675 Acc: 1.0000\n",
      "\n",
      "balance on test set 0.47333333333333333, balance on test set 0.58\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.4719 Acc: 0.8467\n",
      "\n",
      "test Loss: 0.2280 Acc: 1.0000\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.1398 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.0703 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.0448 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.0246 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.0164 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.0092 Acc: 1.0000\n",
      "\n",
      "Number of factuals 5\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] \n",
      "Network: [train.py train_VAE]\n",
      "[INFO] \n",
      "Train: [train.py train_VAE]\n",
      "[INFO] init cost variables: [train.py train_VAE]\n",
      "[INFO] it 0/5, vlb -5.542423,  [train.py train_VAE]\n",
      "[INFO] time: 0.381993 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -2.767029 (-inf)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py save]\n",
      "[INFO] it 1/5, vlb -5.119264,  [train.py train_VAE]\n",
      "[INFO] time: 0.405000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.810389 (-2.767029)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 2/5, vlb -5.183279,  [train.py train_VAE]\n",
      "[INFO] time: 0.415999 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -7.248141 (-2.767029)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 3/5, vlb -5.213056,  [train.py train_VAE]\n",
      "[INFO] time: 0.419999 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.078288 (-2.767029)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 4/5, vlb -5.163746,  [train.py train_VAE]\n",
      "[INFO] time: 0.400997 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -10.165945 (-2.767029)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models/theta_last.dat\n",
      " [utils.py save]\n",
      "[INFO] average time: 0.451599 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "RESULTS: [train.py train_VAE]\n",
      "[INFO] best_vlb_dev: -2.767029 [train.py train_VAE]\n",
      "[INFO] best_vlb_train: -5.119264 [train.py train_VAE]\n",
      "[INFO] nb_parameters: 1006 (1006.00B)\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] Reading C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py load]\n",
      "[INFO] restoring epoch: 1, lr: 0.000100 [utils.py load]\n",
      "Number of counterfactuals: 0\n",
      "Number of factuals 5\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "Number of counterfactuals: 5\n",
      "balance on test set 0.5133333333333333, balance on test set 0.46\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.4670 Acc: 0.7733\n",
      "\n",
      "test Loss: 0.3310 Acc: 1.0000\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.2268 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.1741 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.1229 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.0964 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.0686 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.0554 Acc: 1.0000\n",
      "\n",
      "balance on test set 0.5, balance on test set 0.6\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.6264 Acc: 0.8067\n",
      "\n",
      "test Loss: 0.5415 Acc: 0.9400\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.4124 Acc: 0.9667\n",
      "\n",
      "test Loss: 0.3523 Acc: 0.9800\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.2624 Acc: 0.9733\n",
      "\n",
      "test Loss: 0.2263 Acc: 0.9800\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1675 Acc: 0.9733\n",
      "\n",
      "test Loss: 0.1486 Acc: 0.9800\n",
      "\n",
      "Number of factuals 5\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] \n",
      "Network: [train.py train_VAE]\n",
      "[INFO] \n",
      "Train: [train.py train_VAE]\n",
      "[INFO] init cost variables: [train.py train_VAE]\n",
      "[INFO] it 0/5, vlb -5.542423,  [train.py train_VAE]\n",
      "[INFO] time: 0.502992 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -2.767029 (-inf)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py save]\n",
      "[INFO] it 1/5, vlb -5.119264,  [train.py train_VAE]\n",
      "[INFO] time: 0.465996 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.810389 (-2.767029)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 2/5, vlb -5.183279,  [train.py train_VAE]\n",
      "[INFO] time: 0.456999 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -7.248141 (-2.767029)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 3/5, vlb -5.213056,  [train.py train_VAE]\n",
      "[INFO] time: 0.511001 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.078288 (-2.767029)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 4/5, vlb -5.163746,  [train.py train_VAE]\n",
      "[INFO] time: 0.502000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -10.165945 (-2.767029)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models/theta_last.dat\n",
      " [utils.py save]\n",
      "[INFO] average time: 0.536198 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "RESULTS: [train.py train_VAE]\n",
      "[INFO] best_vlb_dev: -2.767029 [train.py train_VAE]\n",
      "[INFO] best_vlb_train: -5.119264 [train.py train_VAE]\n",
      "[INFO] nb_parameters: 1006 (1006.00B)\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] Reading C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py load]\n",
      "[INFO] restoring epoch: 1, lr: 0.000100 [utils.py load]\n",
      "Number of counterfactuals: 1\n",
      "Number of factuals 5\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "Number of counterfactuals: 5\n",
      "balance on test set 0.52, balance on test set 0.46\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.4679 Acc: 0.7600\n",
      "\n",
      "test Loss: 0.3333 Acc: 1.0000\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.2288 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.1769 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.1262 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.0990 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.0729 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.0584 Acc: 1.0000\n",
      "\n",
      "balance on test set 0.5266666666666666, balance on test set 0.62\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 0.7667\n",
      "\n",
      "test Loss: 0.5337 Acc: 0.9800\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.3795 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.2450 Acc: 0.9800\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.1736 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.1108 Acc: 0.9800\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.0841 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.0621 Acc: 0.9800\n",
      "\n",
      "Number of factuals 5\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] \n",
      "Network: [train.py train_VAE]\n",
      "[INFO] \n",
      "Train: [train.py train_VAE]\n",
      "[INFO] init cost variables: [train.py train_VAE]\n",
      "[INFO] it 0/5, vlb -5.537048,  [train.py train_VAE]\n",
      "[INFO] time: 0.361949 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -2.763392 (-inf)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py save]\n",
      "[INFO] it 1/5, vlb -5.133230,  [train.py train_VAE]\n",
      "[INFO] time: 0.400996 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.797897 (-2.763392)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 2/5, vlb -5.175825,  [train.py train_VAE]\n",
      "[INFO] time: 0.374999 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -4.895127 (-2.763392)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 3/5, vlb -5.202382,  [train.py train_VAE]\n",
      "[INFO] time: 0.380998 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.067954 (-2.763392)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 4/5, vlb -5.156931,  [train.py train_VAE]\n",
      "[INFO] time: 0.362998 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -10.047453 (-2.763392)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models/theta_last.dat\n",
      " [utils.py save]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] average time: 0.416590 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "RESULTS: [train.py train_VAE]\n",
      "[INFO] best_vlb_dev: -2.763392 [train.py train_VAE]\n",
      "[INFO] best_vlb_train: -5.133230 [train.py train_VAE]\n",
      "[INFO] nb_parameters: 1006 (1006.00B)\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] Reading C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py load]\n",
      "[INFO] restoring epoch: 1, lr: 0.000100 [utils.py load]\n",
      "Number of counterfactuals: 5\n",
      "Number of factuals 5\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "Number of counterfactuals: 5\n",
      "balance on test set 0.54, balance on test set 0.5\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.4665 Acc: 0.7600\n",
      "\n",
      "test Loss: 0.3335 Acc: 0.9800\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.2391 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.1956 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.1423 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1264 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.0921 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.0886 Acc: 1.0000\n",
      "\n",
      "balance on test set 0.5466666666666666, balance on test set 0.64\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.6214 Acc: 0.7267\n",
      "\n",
      "test Loss: 0.4848 Acc: 0.9800\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.3513 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.2327 Acc: 0.9800\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.1713 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.1195 Acc: 0.9800\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.0927 Acc: 0.9867\n",
      "\n",
      "test Loss: 0.0737 Acc: 0.9800\n",
      "\n",
      "Number of factuals 5\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] \n",
      "Network: [train.py train_VAE]\n",
      "[INFO] \n",
      "Train: [train.py train_VAE]\n",
      "[INFO] init cost variables: [train.py train_VAE]\n",
      "[INFO] it 0/5, vlb -5.515216,  [train.py train_VAE]\n",
      "[INFO] time: 0.392972 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -2.683741 (-inf)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py save]\n",
      "[INFO] it 1/5, vlb -5.371174,  [train.py train_VAE]\n",
      "[INFO] time: 0.357002 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.412575 (-2.683741)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 2/5, vlb -5.222647,  [train.py train_VAE]\n",
      "[INFO] time: 0.368000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -4.960714 (-2.683741)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 3/5, vlb -5.128109,  [train.py train_VAE]\n",
      "[INFO] time: 0.389998 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.104747 (-2.683741)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 4/5, vlb -5.131464,  [train.py train_VAE]\n",
      "[INFO] time: 0.357000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -8.211440 (-2.683741)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models/theta_last.dat\n",
      " [utils.py save]\n",
      "[INFO] average time: 0.408994 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "RESULTS: [train.py train_VAE]\n",
      "[INFO] best_vlb_dev: -2.683741 [train.py train_VAE]\n",
      "[INFO] best_vlb_train: -5.128109 [train.py train_VAE]\n",
      "[INFO] nb_parameters: 1006 (1006.00B)\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] Reading C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py load]\n",
      "[INFO] restoring epoch: 1, lr: 0.000100 [utils.py load]\n",
      "Number of counterfactuals: 5\n",
      "Number of factuals 5\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "Number of counterfactuals: 5\n",
      "balance on test set 0.5733333333333334, balance on test set 0.5\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.4712 Acc: 0.7067\n",
      "\n",
      "test Loss: 0.3524 Acc: 0.9400\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.2602 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.2178 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.1710 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1438 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1243 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1056 Acc: 1.0000\n",
      "\n",
      "balance on test set 0.5666666666666667, balance on test set 0.68\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.6286 Acc: 0.6267\n",
      "\n",
      "test Loss: 0.5031 Acc: 1.0000\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.3881 Acc: 0.9667\n",
      "\n",
      "test Loss: 0.2676 Acc: 0.9800\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.2017 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.1552 Acc: 0.9800\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1125 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.0967 Acc: 1.0000\n",
      "\n",
      "Number of factuals 5\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] \n",
      "Network: [train.py train_VAE]\n",
      "[INFO] \n",
      "Train: [train.py train_VAE]\n",
      "[INFO] init cost variables: [train.py train_VAE]\n",
      "[INFO] it 0/5, vlb -5.568170,  [train.py train_VAE]\n",
      "[INFO] time: 0.421993 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -2.690422 (-inf)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py save]\n",
      "[INFO] it 1/5, vlb -5.347620,  [train.py train_VAE]\n",
      "[INFO] time: 0.553000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.417815 (-2.690422)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 2/5, vlb -5.235084,  [train.py train_VAE]\n",
      "[INFO] time: 0.414000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -4.729555 (-2.690422)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 3/5, vlb -5.110400,  [train.py train_VAE]\n",
      "[INFO] time: 0.387999 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.085628 (-2.690422)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 4/5, vlb -5.166015,  [train.py train_VAE]\n",
      "[INFO] time: 0.434004 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -4.677879 (-2.690422)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models/theta_last.dat\n",
      " [utils.py save]\n",
      "[INFO] average time: 0.482801 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "RESULTS: [train.py train_VAE]\n",
      "[INFO] best_vlb_dev: -2.690422 [train.py train_VAE]\n",
      "[INFO] best_vlb_train: -5.110400 [train.py train_VAE]\n",
      "[INFO] nb_parameters: 1006 (1006.00B)\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] Reading C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py load]\n",
      "[INFO] restoring epoch: 1, lr: 0.000100 [utils.py load]\n",
      "Number of counterfactuals: 5\n",
      "Number of factuals 5\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "Number of counterfactuals: 5\n",
      "balance on test set 0.5933333333333334, balance on test set 0.52\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.4686 Acc: 0.6733\n",
      "\n",
      "test Loss: 0.3595 Acc: 0.9000\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.2673 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.2347 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.1820 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1629 Acc: 0.9800\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1373 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1259 Acc: 1.0000\n",
      "\n",
      "balance on test set 0.5933333333333334, balance on test set 0.68\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.6254 Acc: 0.6000\n",
      "\n",
      "test Loss: 0.5152 Acc: 0.9400\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.4331 Acc: 0.8867\n",
      "\n",
      "test Loss: 0.3183 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.2594 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.1795 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1513 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1108 Acc: 1.0000\n",
      "\n",
      "Number of factuals 5\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] \n",
      "Network: [train.py train_VAE]\n",
      "[INFO] \n",
      "Train: [train.py train_VAE]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] init cost variables: [train.py train_VAE]\n",
      "[INFO] it 0/5, vlb -5.488476,  [train.py train_VAE]\n",
      "[INFO] time: 0.363000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -2.665203 (-inf)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py save]\n",
      "[INFO] it 1/5, vlb -5.342568,  [train.py train_VAE]\n",
      "[INFO] time: 0.359000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.408636 (-2.665203)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 2/5, vlb -5.208235,  [train.py train_VAE]\n",
      "[INFO] time: 0.377002 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -5.450520 (-2.665203)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 3/5, vlb -5.117366,  [train.py train_VAE]\n",
      "[INFO] time: 0.372000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.092664 (-2.665203)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 4/5, vlb -5.124391,  [train.py train_VAE]\n",
      "[INFO] time: 0.370001 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.671736 (-2.665203)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models/theta_last.dat\n",
      " [utils.py save]\n",
      "[INFO] average time: 0.406800 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "RESULTS: [train.py train_VAE]\n",
      "[INFO] best_vlb_dev: -2.665203 [train.py train_VAE]\n",
      "[INFO] best_vlb_train: -5.117366 [train.py train_VAE]\n",
      "[INFO] nb_parameters: 1006 (1006.00B)\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] Reading C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py load]\n",
      "[INFO] restoring epoch: 1, lr: 0.000100 [utils.py load]\n",
      "Number of counterfactuals: 5\n",
      "Number of factuals 5\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "Number of counterfactuals: 5\n",
      "balance on test set 0.6066666666666667, balance on test set 0.54\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.4663 Acc: 0.6733\n",
      "\n",
      "test Loss: 0.3628 Acc: 0.8600\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.2738 Acc: 0.9867\n",
      "\n",
      "test Loss: 0.2423 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.1935 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1742 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1485 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1390 Acc: 1.0000\n",
      "\n",
      "balance on test set 0.6133333333333333, balance on test set 0.68\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.6205 Acc: 0.6000\n",
      "\n",
      "test Loss: 0.5147 Acc: 0.8400\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.4431 Acc: 0.8267\n",
      "\n",
      "test Loss: 0.3293 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.2863 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.1998 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1821 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1292 Acc: 1.0000\n",
      "\n",
      "Number of factuals 5\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] \n",
      "Network: [train.py train_VAE]\n",
      "[INFO] \n",
      "Train: [train.py train_VAE]\n",
      "[INFO] init cost variables: [train.py train_VAE]\n",
      "[INFO] it 0/5, vlb -5.501046,  [train.py train_VAE]\n",
      "[INFO] time: 0.403996 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -2.622487 (-inf)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py save]\n",
      "[INFO] it 1/5, vlb -5.294972,  [train.py train_VAE]\n",
      "[INFO] time: 0.399999 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.355091 (-2.622487)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 2/5, vlb -5.227873,  [train.py train_VAE]\n",
      "[INFO] time: 0.406000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -8.380405 (-2.622487)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 3/5, vlb -5.097148,  [train.py train_VAE]\n",
      "[INFO] time: 0.416003 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.048495 (-2.622487)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 4/5, vlb -5.145972,  [train.py train_VAE]\n",
      "[INFO] time: 0.425999 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.480524 (-2.622487)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models/theta_last.dat\n",
      " [utils.py save]\n",
      "[INFO] average time: 0.453999 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "RESULTS: [train.py train_VAE]\n",
      "[INFO] best_vlb_dev: -2.622487 [train.py train_VAE]\n",
      "[INFO] best_vlb_train: -5.097148 [train.py train_VAE]\n",
      "[INFO] nb_parameters: 1006 (1006.00B)\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] Reading C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py load]\n",
      "[INFO] restoring epoch: 1, lr: 0.000100 [utils.py load]\n",
      "Number of counterfactuals: 5\n",
      "Number of factuals 5\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "Number of counterfactuals: 5\n",
      "balance on test set 0.6266666666666667, balance on test set 0.56\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.4622 Acc: 0.6600\n",
      "\n",
      "test Loss: 0.3683 Acc: 0.8200\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.2788 Acc: 0.9467\n",
      "\n",
      "test Loss: 0.2540 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.2018 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.1900 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1585 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1539 Acc: 1.0000\n",
      "\n",
      "balance on test set 0.6333333333333333, balance on test set 0.7\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.6139 Acc: 0.6200\n",
      "\n",
      "test Loss: 0.5040 Acc: 0.7000\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.4447 Acc: 0.7867\n",
      "\n",
      "test Loss: 0.3367 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.2958 Acc: 0.9867\n",
      "\n",
      "test Loss: 0.2132 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1963 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1424 Acc: 1.0000\n",
      "\n",
      "Number of factuals 5\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] \n",
      "Network: [train.py train_VAE]\n",
      "[INFO] \n",
      "Train: [train.py train_VAE]\n",
      "[INFO] init cost variables: [train.py train_VAE]\n",
      "[INFO] it 0/5, vlb -5.486189,  [train.py train_VAE]\n",
      "[INFO] time: 0.385000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -2.595575 (-inf)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py save]\n",
      "[INFO] it 1/5, vlb -5.351483,  [train.py train_VAE]\n",
      "[INFO] time: 0.394000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.452755 (-2.595575)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 2/5, vlb -5.225058,  [train.py train_VAE]\n",
      "[INFO] time: 0.401998 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -4.997950 (-2.595575)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 3/5, vlb -5.111756,  [train.py train_VAE]\n",
      "[INFO] time: 0.413998 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.026192 (-2.595575)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 4/5, vlb -5.119704,  [train.py train_VAE]\n",
      "[INFO] time: 0.412992 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -4.065386 (-2.595575)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models/theta_last.dat\n",
      " [utils.py save]\n",
      "[INFO] average time: 0.446000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "RESULTS: [train.py train_VAE]\n",
      "[INFO] best_vlb_dev: -2.595575 [train.py train_VAE]\n",
      "[INFO] best_vlb_train: -5.111756 [train.py train_VAE]\n",
      "[INFO] nb_parameters: 1006 (1006.00B)\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] Reading C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py load]\n",
      "[INFO] restoring epoch: 1, lr: 0.000100 [utils.py load]\n",
      "Number of counterfactuals: 5\n",
      "Number of factuals 5\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of counterfactuals: 5\n",
      "balance on test set 0.64, balance on test set 0.56\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.4599 Acc: 0.6667\n",
      "\n",
      "test Loss: 0.3805 Acc: 0.8000\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.2837 Acc: 0.9267\n",
      "\n",
      "test Loss: 0.2653 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.2085 Acc: 0.9933\n",
      "\n",
      "test Loss: 0.2018 Acc: 0.9800\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1642 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1672 Acc: 1.0000\n",
      "\n",
      "balance on test set 0.6466666666666666, balance on test set 0.7\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.5908 Acc: 0.6400\n",
      "\n",
      "test Loss: 0.4748 Acc: 0.7000\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.4216 Acc: 0.7800\n",
      "\n",
      "test Loss: 0.3085 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.2820 Acc: 0.9867\n",
      "\n",
      "test Loss: 0.2031 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1906 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1432 Acc: 1.0000\n",
      "\n",
      "Number of factuals 5\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] \n",
      "Network: [train.py train_VAE]\n",
      "[INFO] \n",
      "Train: [train.py train_VAE]\n",
      "[INFO] init cost variables: [train.py train_VAE]\n",
      "[INFO] it 0/5, vlb -5.521287,  [train.py train_VAE]\n",
      "[INFO] time: 0.379998 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -2.615638 (-inf)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py save]\n",
      "[INFO] it 1/5, vlb -5.314244,  [train.py train_VAE]\n",
      "[INFO] time: 0.358005 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.442250 (-2.615638)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 2/5, vlb -5.225329,  [train.py train_VAE]\n",
      "[INFO] time: 0.381999 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -4.798303 (-2.615638)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 3/5, vlb -5.165519,  [train.py train_VAE]\n",
      "[INFO] time: 0.368997 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.012440 (-2.615638)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 4/5, vlb -5.176495,  [train.py train_VAE]\n",
      "[INFO] time: 0.365001 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.904924 (-2.615638)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models/theta_last.dat\n",
      " [utils.py save]\n",
      "[INFO] average time: 0.406600 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "RESULTS: [train.py train_VAE]\n",
      "[INFO] best_vlb_dev: -2.615638 [train.py train_VAE]\n",
      "[INFO] best_vlb_train: -5.165519 [train.py train_VAE]\n",
      "[INFO] nb_parameters: 1006 (1006.00B)\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] Reading C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py load]\n",
      "[INFO] restoring epoch: 1, lr: 0.000100 [utils.py load]\n",
      "Number of counterfactuals: 5\n",
      "Number of factuals 5\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "Number of counterfactuals: 5\n",
      "balance on test set 0.6466666666666666, balance on test set 0.6\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.4598 Acc: 0.6667\n",
      "\n",
      "test Loss: 0.3748 Acc: 0.7000\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.2894 Acc: 0.9200\n",
      "\n",
      "test Loss: 0.2670 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.2181 Acc: 0.9867\n",
      "\n",
      "test Loss: 0.2103 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.1752 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1783 Acc: 1.0000\n",
      "\n",
      "balance on test set 0.6666666666666666, balance on test set 0.7\n",
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.5808 Acc: 0.6600\n",
      "\n",
      "test Loss: 0.4673 Acc: 0.7000\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.4236 Acc: 0.7333\n",
      "\n",
      "test Loss: 0.3200 Acc: 1.0000\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.2961 Acc: 0.9800\n",
      "\n",
      "test Loss: 0.2142 Acc: 1.0000\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.2032 Acc: 1.0000\n",
      "\n",
      "test Loss: 0.1526 Acc: 1.0000\n",
      "\n",
      "Number of factuals 5\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] \n",
      "Network: [train.py train_VAE]\n",
      "[INFO] \n",
      "Train: [train.py train_VAE]\n",
      "[INFO] init cost variables: [train.py train_VAE]\n",
      "[INFO] it 0/5, vlb -5.481059,  [train.py train_VAE]\n",
      "[INFO] time: 0.381994 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -2.649299 (-inf)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py save]\n",
      "[INFO] it 1/5, vlb -5.312709,  [train.py train_VAE]\n",
      "[INFO] time: 0.394998 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.631238 (-2.649299)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 2/5, vlb -5.222069,  [train.py train_VAE]\n",
      "[INFO] time: 0.403001 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -5.007973 (-2.649299)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 3/5, vlb -5.114132,  [train.py train_VAE]\n",
      "[INFO] time: 0.383000 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -3.216826 (-2.649299)\n",
      " [train.py train_VAE]\n",
      "[INFO] it 4/5, vlb -5.154925,  [train.py train_VAE]\n",
      "[INFO] time: 0.397999 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] vlb -4.254843 (-2.649299)\n",
      " [train.py train_VAE]\n",
      "[INFO] Writting C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models/theta_last.dat\n",
      " [utils.py save]\n",
      "[INFO] average time: 0.435799 seconds\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "RESULTS: [train.py train_VAE]\n",
      "[INFO] best_vlb_dev: -2.649299 [train.py train_VAE]\n",
      "[INFO] best_vlb_train: -5.114132 [train.py train_VAE]\n",
      "[INFO] nb_parameters: 1006 (1006.00B)\n",
      " [train.py train_VAE]\n",
      "[INFO] \n",
      "Net: [utils.py __init__]\n",
      "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
      "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
      "[INFO] Reading C:\\Users\\drobi\\carla\\models\\autoencoders\\clue\\fc_VAE_custom_models\\theta_best.dat\n",
      " [utils.py load]\n",
      "[INFO] restoring epoch: 1, lr: 0.000100 [utils.py load]\n",
      "Number of counterfactuals: 5\n",
      "Number of factuals 5\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "Number of counterfactuals: 5\n"
     ]
    }
   ],
   "source": [
    "iter_id += 1\n",
    "dataset = load_dataset()\n",
    "\n",
    "clue_dataset = load_dataset()\n",
    "clue_result = get_empty_results()\n",
    "results['clue'] = clue_result\n",
    "\n",
    "wachter_dataset = load_dataset()\n",
    "wachter_result = get_empty_results()\n",
    "results['wachter'] = wachter_result\n",
    "\n",
    "iterations = 10\n",
    "samples = 5\n",
    "\n",
    "for i in range(iterations):\n",
    "    clue_model, clue_factuals = get_factuals(clue_dataset, sample_num=samples)\n",
    "    wachter_model, wachter_factuals = get_factuals(wachter_dataset, sample_num=samples)\n",
    "    \n",
    "    factuals = pd.merge(clue_factuals, wachter_factuals, how='inner', on=[*dataset.continuous, dataset.target])\n",
    "    factuals = pd.merge(factuals, dataset._df, how='inner', on=dataset.continuous)\n",
    "    \n",
    "    if len(factuals) > samples:\n",
    "        factuals = factuals.sample(samples)\n",
    "    \n",
    "    execute_experiment_iteration('clue', clue_dataset, clue_model, factuals, clue_result)\n",
    "    execute_experiment_iteration('wachter', wachter_dataset, wachter_model, factuals, wachter_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0a9a946c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clue': {'datasets': [     feature1  feature2  target\n",
       "   0    0.080272  0.274545     0.0\n",
       "   1    0.241592  0.065763     0.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.066525  0.280942     0.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.080272  0.274545     0.0\n",
       "   1    0.241592  0.065763     0.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.066525  0.280942     0.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.080272  0.274545     0.0\n",
       "   1    0.286756  0.436256     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.066525  0.280942     0.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.080272  0.274545     0.0\n",
       "   1    0.286756  0.436256     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.066525  0.280942     0.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.080272  0.274545     0.0\n",
       "   1    0.286756  0.436256     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.066525  0.280942     0.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.399756  0.311512     1.0\n",
       "   1    0.286756  0.436256     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.066525  0.280942     0.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.399756  0.311512     1.0\n",
       "   1    0.286756  0.436256     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.066525  0.280942     0.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.322693  0.274183     1.0\n",
       "   1    0.286756  0.436256     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.066525  0.280942     0.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.322693  0.274183     1.0\n",
       "   1    0.286756  0.436256     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.066525  0.280942     0.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.322693  0.274183     1.0\n",
       "   1    0.286756  0.436256     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.066525  0.280942     0.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns]],\n",
       "  'means': [array([0.46975977, 0.43095196]),\n",
       "   array([0.46993454, 0.43278277]),\n",
       "   array([0.47116883, 0.44064993]),\n",
       "   array([0.47416013, 0.44555454]),\n",
       "   array([0.47466434, 0.45091747]),\n",
       "   array([0.47586322, 0.45317285]),\n",
       "   array([0.47623863, 0.45852839]),\n",
       "   array([0.48022387, 0.45829648]),\n",
       "   array([0.47762402, 0.46350085]),\n",
       "   array([0.47899081, 0.46311674])],\n",
       "  'covariances': [array([[0.07549703, 0.06332892],\n",
       "          [0.06332892, 0.07842307]]),\n",
       "   array([[0.07541842, 0.06290834],\n",
       "          [0.06290834, 0.07823808]]),\n",
       "   array([[0.07479147, 0.06115816],\n",
       "          [0.06115816, 0.07564169]]),\n",
       "   array([[0.07361561, 0.05960449],\n",
       "          [0.05960449, 0.07357159]]),\n",
       "   array([[0.07340194, 0.05852291],\n",
       "          [0.05852291, 0.07136728]]),\n",
       "   array([[0.07286731, 0.05756515],\n",
       "          [0.05756515, 0.07088378]]),\n",
       "   array([[0.07273247, 0.056184  ],\n",
       "          [0.056184  , 0.06892731]]),\n",
       "   array([[0.07196784, 0.05496932],\n",
       "          [0.05496932, 0.06926214]]),\n",
       "   array([[0.07224604, 0.05431162],\n",
       "          [0.05431162, 0.06703075]]),\n",
       "   array([[0.07146831, 0.05429839],\n",
       "          [0.05429839, 0.06654364]])],\n",
       "  'clustering': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  'accuracies': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  'f1_scores': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  'benchmark': []},\n",
       " 'wachter': {'datasets': [     feature1  feature2  target\n",
       "   0    0.080272  0.274545     0.0\n",
       "   1    0.241592  0.065763     0.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.066525  0.280942     0.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.080272  0.274545     0.0\n",
       "   1    0.241592  0.065763     0.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.418858  0.633257     1.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.080272  0.274545     0.0\n",
       "   1    0.510636  0.334788     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.418858  0.633257     1.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.080272  0.274545     0.0\n",
       "   1    0.510636  0.334788     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.418858  0.633257     1.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.080272  0.274545     0.0\n",
       "   1    0.510636  0.334788     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.418858  0.633257     1.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.320983  0.515231     1.0\n",
       "   1    0.510636  0.334788     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.418858  0.633257     1.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.320983  0.515231     1.0\n",
       "   1    0.510636  0.334788     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.418858  0.633257     1.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.336693  0.395460     1.0\n",
       "   1    0.510636  0.334788     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.418858  0.633257     1.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.336693  0.395460     1.0\n",
       "   1    0.510636  0.334788     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.418858  0.633257     1.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns],\n",
       "        feature1  feature2  target\n",
       "   0    0.336693  0.395460     1.0\n",
       "   1    0.510636  0.334788     1.0\n",
       "   2    0.096065  0.154848     0.0\n",
       "   3    0.418858  0.633257     1.0\n",
       "   4    0.195372  0.167314     0.0\n",
       "   ..        ...       ...     ...\n",
       "   195  0.885143  0.624946     1.0\n",
       "   196  0.773658  0.672115     1.0\n",
       "   197  0.826296  0.632205     1.0\n",
       "   198  0.898391  0.558944     1.0\n",
       "   199  0.782078  0.761226     1.0\n",
       "   \n",
       "   [200 rows x 3 columns]],\n",
       "  'means': [array([0.47591433, 0.43710651]),\n",
       "   array([0.48397208, 0.44506266]),\n",
       "   array([0.48853593, 0.4500247 ]),\n",
       "   array([0.49358794, 0.45719103]),\n",
       "   array([0.49569628, 0.46361924]),\n",
       "   array([0.49846013, 0.46648398]),\n",
       "   array([0.50156848, 0.47083174]),\n",
       "   array([0.50496482, 0.46946526]),\n",
       "   array([0.50559406, 0.47484766]),\n",
       "   array([0.50754655, 0.47472994])],\n",
       "  'covariances': [array([[0.07319617, 0.0616377 ],\n",
       "          [0.0616377 , 0.07734148]]),\n",
       "   array([[0.07137641, 0.0598218 ],\n",
       "          [0.0598218 , 0.07557917]]),\n",
       "   array([[0.06990308, 0.0581802 ],\n",
       "          [0.0581802 , 0.07362194]]),\n",
       "   array([[0.06821388, 0.05602408],\n",
       "          [0.05602408, 0.07125706]]),\n",
       "   array([[0.06750536, 0.05463819],\n",
       "          [0.05463819, 0.06860268]]),\n",
       "   array([[0.06606096, 0.05351798],\n",
       "          [0.05351798, 0.06790145]]),\n",
       "   array([[0.0649101 , 0.05190217],\n",
       "          [0.05190217, 0.06599213]]),\n",
       "   array([[0.06360241, 0.05119095],\n",
       "          [0.05119095, 0.06604748]]),\n",
       "   array([[0.06324456, 0.0499091 ],\n",
       "          [0.0499091 , 0.06360142]]),\n",
       "   array([[0.06241401, 0.04936596],\n",
       "          [0.04936596, 0.06328618]])],\n",
       "  'clustering': [2, 2, 2, 2, 2, 2, 9, 2, 2, 2],\n",
       "  'accuracies': [1.0, 0.975, 0.985, 0.995, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  'f1_scores': [1.0,\n",
       "   0.9767441860465117,\n",
       "   0.9866666666666666,\n",
       "   0.9957805907172996,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'benchmark': []}}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "aa0c4754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved gif to gifs/clue_gif_2.gif\n"
     ]
    }
   ],
   "source": [
    "generate_animation(results, 'clue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d1894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recourse2",
   "language": "python",
   "name": "recourse2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
